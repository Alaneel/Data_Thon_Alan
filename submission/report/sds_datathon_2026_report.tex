\documentclass[11pt,a4paper]{article}

% ============================================================
% PACKAGES
% ============================================================
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[margin=2.5cm]{geometry}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}
\usepackage{longtable}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{float}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{listings}
\usepackage{natbib}
\usepackage{abstract}

% ============================================================
% STYLING
% ============================================================
\hypersetup{
    colorlinks=true,
    linkcolor=blue!70!black,
    citecolor=green!50!black,
    urlcolor=blue!70!black
}

% Section formatting
\titleformat{\section}{\Large\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}{\large\bfseries}{\thesubsection}{1em}{}
\titleformat{\subsubsection}{\normalsize\bfseries}{\thesubsubsection}{1em}{}

% Header and footer
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\small SDS Datathon 2026}
\fancyhead[R]{\small AI-Driven Company Intelligence}
\fancyfoot[C]{\thepage}
\renewcommand{\headrulewidth}{0.4pt}

% Code listing style
\lstset{
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=single,
    backgroundcolor=\color{gray!10}
}

% ============================================================
% DOCUMENT INFO
% ============================================================
\title{
    \vspace{-1cm}
    \textbf{AI-Driven Company Intelligence Through Data-Driven Segmentation} \\
    \vspace{0.3cm}
    \large SDS Datathon 2026 - Final Report
}

\author{
    Team Submission \\
    \textit{Singapore Data Science Datathon 2026}
}

\date{January 2026}

% ============================================================
% DOCUMENT
% ============================================================
\begin{document}

\maketitle

\begin{abstract}
This paper presents a prototype system for deriving actionable business intelligence from company-level data through multi-dimensional clustering, lead scoring, and risk detection. We analyze 8,559 companies from the Champions Group dataset, engineering 15+ features across organizational structure, productivity, and data quality dimensions. Using K-Means clustering ($k=5$, silhouette score: 0.48) combined with Isolation Forest anomaly detection, we segment companies into interpretable market tiers and identify 3,063 potential shell companies and 428 statistical anomalies. Our B2B lead scoring model achieves meaningful stratification with 3 priority leads, 425 hot leads, and demonstrates clear dataset monetization potential. Integration with Large Language Models (LLMs) enables natural language insight generation, fulfilling the bonus requirement of interpretable explanations.
\end{abstract}

\tableofcontents
\newpage

% ============================================================
% 1. INTRODUCTION
% ============================================================
\section{Introduction}
\label{sec:introduction}

\subsection{Background and Motivation}

The modern B2B marketplace is characterized by an overwhelming volume of company data, yet extracting actionable business intelligence remains a significant challenge \citep{chen2012business}. Decision-makers across sales, marketing, investment, and risk management functions need efficient tools to segment markets, identify high-value prospects, and detect potential risks \citep{provost2013data}.

Traditional approaches to company analysis often rely on manual review or simple filtering, which fails to capture the multi-dimensional nature of business entities. Machine learning techniques, particularly unsupervised clustering, offer promising solutions for discovering natural groupings within company data \citep{jain2010data}.

\subsection{Project Objectives}

This project develops a prototype system that transforms raw company-level data into interpretable business intelligence. By leveraging data analytics, machine learning techniques, and large language models (LLMs), our system generates data-grounded insights that help users understand how companies operate and compare with similar firms \citep{vaswani2017attention}.

Our solution enables users to:
\begin{itemize}[noitemsep]
    \item Identify and group companies with similar characteristics or operating profiles
    \item Understand key differences and similarities within and across groups
    \item Highlight notable patterns, strengths, risks, or anomalies
    \item Demonstrate commercial value through actionable lead scoring and risk assessment
    \item Generate interpretable, data-grounded explanations using LLM integration
\end{itemize}

\subsection{Commercial Value Proposition}

The insights generated directly support multiple business functions:
\begin{itemize}[noitemsep]
    \item \textbf{Sales teams}: Prioritized lead lists based on quantitative scoring
    \item \textbf{Risk analysts}: Automated anomaly detection and shell company identification
    \item \textbf{Strategic planners}: Industry benchmarking and competitive positioning
    \item \textbf{Data buyers}: Demonstrated dataset monetization potential
\end{itemize}

% ============================================================
% 2. DATASET OVERVIEW
% ============================================================
\section{Dataset Overview}
\label{sec:dataset}

\subsection{Data Description and Scope}

The dataset contains 8,559 company records with 72 attributes. Each row represents a unique business entity with no duplicates. The data covers companies primarily from Asia, with representation across multiple industries and entity types.

Table \ref{tab:data_categories} summarizes the key column categories:

\begin{table}[H]
\centering
\caption{Dataset Column Categories}
\label{tab:data_categories}
\begin{tabular}{lp{7cm}c}
\toprule
\textbf{Category} & \textbf{Key Columns} & \textbf{Count} \\
\midrule
Identity \& Contact & DUNS Number, Company Sites, Website, Phone & 12 \\
Geographic & City, State, Region, Country, Postal Code & 12 \\
Industry Classification & SIC, NAICS, NACE, ANZSIC, ISIC codes & 14 \\
Financial Metrics & Revenue (USD), Market Value (USD) & 2 \\
Organizational Size & Employees Total, Employees Single Site & 2 \\
Corporate Structure & Entity Type, Parent Company, Ultimate entities & 15 \\
IT Infrastructure & IT Spend, IT Budget, Device counts & 10 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Data Quality Assessment}

Initial analysis revealed several data quality challenges:

\begin{itemize}[noitemsep]
    \item \textbf{Missing Financial Data}: Revenue missing/zero in $\sim$35\% of records; Employees missing/zero in $\sim$15\%
    \item \textbf{Skewed Distributions}: Both revenue and employee counts exhibit heavy right-skew
    \item \textbf{Mixed Data Types}: Numeric fields stored as strings required preprocessing
    \item \textbf{Incomplete Hierarchy}: Parent company linkages not always present
\end{itemize}

\subsection{Feature Selection Rationale}

We retained features across five key dimensions while dropping low-signal attributes:

\textbf{Retained Features:}
\begin{itemize}[noitemsep]
    \item \textbf{Geographic}: Country, Region, City/State
    \item \textbf{Firmographics}: SIC Code/Description, Year Found, Entity Type
    \item \textbf{Financial}: Revenue (USD), Employees Total, Market Value, IT Spend
    \item \textbf{Ownership}: Parent Company, Global/Domestic Ultimate, Corporate Family Size
    \item \textbf{Strategic}: Is Headquarters, Ownership Type
\end{itemize}

\textbf{Dropped Features} (with rationale):
\begin{itemize}[noitemsep]
    \item Pure identifiers (DUNS, Registration Numbers) -- no analytical value
    \item Contact details (Website, Phone) -- operational, not analytical
    \item Street-level addresses -- too granular for segmentation
    \item Redundant industry codes -- kept only SIC and NAICS
    \item Granular IT inventory -- kept only IT Spend as summary metric
\end{itemize}

% ============================================================
% 3. METHODOLOGY
% ============================================================
\section{Methodology}
\label{sec:methodology}

\subsection{Data Cleaning and Normalization}

\subsubsection{Missing Value Handling}

We implement a sophisticated missing value strategy using K-Nearest Neighbors (KNN) imputation \citep{troyanskaya2001missing}:

\begin{enumerate}[noitemsep]
    \item Create binary flags: \texttt{Is\_Revenue\_Missing}, \texttt{Is\_Employees\_Missing}
    \item Replace zeros with NaN for imputation
    \item Apply log transformation: $x' = \log(1 + x)$
    \item Add Entity Type ordinal as context feature
    \item Standardize using Z-score normalization
    \item Apply KNN Imputer with $k=5$ neighbors
    \item Inverse transform to restore original scale
\end{enumerate}

\subsubsection{Normalization Strategy}

To handle heavy-tailed distributions, we apply:
\begin{equation}
    \text{Log\_Revenue} = \log(1 + \text{Revenue\_USD\_Clean})
\end{equation}
\begin{equation}
    \text{Log\_Employees} = \log(1 + \text{Employees\_Total\_Clean})
\end{equation}

All features are standardized using \texttt{StandardScaler} before modeling \citep{pedregosa2011scikit}.

\subsection{Feature Engineering}

We engineer 15+ features across five conceptual dimensions:

\subsubsection{Organizational Structure}

\textbf{Entity Score} -- a proxy for decision-making autonomy:

\begin{table}[H]
\centering
\caption{Entity Score Mapping}
\label{tab:entity_score}
\begin{tabular}{lcc}
\toprule
\textbf{Entity Type} & \textbf{Score} & \textbf{Rationale} \\
\midrule
Headquarters & 4 & Central decision hub \\
Parent & 3 & Strategic control entity \\
Single Location & 3 & Independent operator \\
Subsidiary & 2 & Operational unit \\
Branch & 1 & Local office, minimal autonomy \\
\bottomrule
\end{tabular}
\end{table}

Additional structural features:
\begin{itemize}[noitemsep]
    \item \texttt{Has\_Parent}: Binary indicator of ownership dependency
    \item \texttt{Is\_Domestic\_Ultimate\_Clean}: Local vs. foreign control
\end{itemize}

\subsubsection{Industry Benchmarking}

We calculate industry-relative performance metrics:
\begin{equation}
    \text{Revenue\_vs\_Industry} = \left(\frac{\text{Revenue}}{\text{Industry\_Median}} - 1\right) \times 100\%
\end{equation}

Values are clipped to $[-100\%, +500\%]$ to handle outliers.

\subsubsection{Productivity Indicators}

\begin{equation}
    \text{Revenue\_Per\_Employee} = \frac{\text{Revenue\_USD\_Clean}}{\text{Employees\_Total\_Clean}}
\end{equation}

\begin{equation}
    \text{Company\_Age} = 2026 - \text{Year\_Found}
\end{equation}

\subsubsection{Data Quality Score}

\begin{equation}
    \text{Data\_Completeness} = \frac{\sum_{i=1}^{7} \mathbf{1}[\text{field}_i \text{ present}]}{7}
\end{equation}

Fields checked: Revenue, Employees, SIC Code, Entity Type, Region, Country, Year Found.

\subsection{Clustering Algorithm}

\subsubsection{Feature Selection for Clustering}

We select 7 features capturing multiple business dimensions:
\begin{enumerate}[noitemsep]
    \item Log\_Revenue -- Financial scale
    \item Log\_Employees -- Organizational scale
    \item Entity\_Score -- Decision-making power
    \item Has\_Parent -- Ownership structure
    \item Revenue\_Per\_Employee -- Productivity
    \item Company\_Age -- Maturity
    \item Is\_Domestic\_Ultimate\_Clean -- Strategic control
\end{enumerate}

\subsubsection{K-Means Clustering}

We apply K-Means clustering \citep{macqueen1967some} with $k=5$ clusters, determined via:
\begin{itemize}[noitemsep]
    \item Elbow Method: Inertia plot analysis
    \item Silhouette Score: $s = 0.4801$
\end{itemize}

\begin{equation}
    \text{Silhouette}(i) = \frac{b(i) - a(i)}{\max(a(i), b(i))}
\end{equation}

where $a(i)$ is intra-cluster distance and $b(i)$ is nearest-cluster distance.

\subsubsection{Dynamic Cluster Naming}

Clusters are named using a two-axis system:
\begin{enumerate}[noitemsep]
    \item \textbf{Tier} (1-5): Based on median revenue rank
    \item \textbf{Structure}: Based on dominant Entity Score
\end{enumerate}

\subsection{Lead Scoring Model}

We implement a multi-factor scoring algorithm (Table \ref{tab:lead_scoring}):

\begin{table}[H]
\centering
\caption{Lead Score Components (v2)}
\label{tab:lead_scoring}
\begin{tabular}{lcp{6cm}}
\toprule
\textbf{Component} & \textbf{Weight} & \textbf{Logic} \\
\midrule
Revenue Potential & 35 & $>$\$100M: 35; $>$\$10M: 25; $>$\$1M: 15 \\
Decision Power & 20 & Domestic Ultimate: 15; else Entity\_Score $\times$ 3 \\
Tech/Efficiency & 20 & Rev/Emp $>$ \$500K: 10; IT Spend present: 10 \\
Market Value & 15 & If Market Value $>$ 0: 15 \\
Stability & 10 & Age 3-10 years: 10; Age $>$10: 5 \\
\midrule
\multicolumn{3}{l}{\textit{Penalty: Score $\times$ 0.8 if Data\_Completeness $<$ 0.5}} \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Risk Detection}

\subsubsection{Rule-Based Risk Flags}

\begin{itemize}[noitemsep]
    \item \textbf{Shell Company}: Revenue $>$ \$100K AND Employees = 0 (missing)
    \item \textbf{Data Quality}: Data\_Completeness $<$ 0.5
    \item \textbf{Orphan Subsidiary}: Entity Type = ``Subsidiary'' AND Has\_Parent = 0
\end{itemize}

\subsubsection{Anomaly Detection}

We apply Isolation Forest \citep{liu2008isolation} for unsupervised anomaly detection:
\begin{itemize}[noitemsep]
    \item Contamination: 5\% (expects 5\% anomalies)
    \item Features: Same 7-feature set as clustering
    \item Output: Anomaly label and continuous anomaly score
\end{itemize}

\subsection{LLM Integration}

We integrate Google Gemini API for natural language insight generation \citep{team2023gemini}:
\begin{itemize}[noitemsep]
    \item Cluster Persona Generation
    \item Anomaly Investigation Reports
    \item Competitive Intelligence Analysis
    \item Action Report Generation
\end{itemize}

\subsection{Deployment: Interactive Intelligence Platform}

The system is deployed as an interactive Streamlit application with three specialized modules:
\begin{enumerate}[noitemsep]
    \item \textbf{Company Explorer}: A searchable interface for individual company analysis, supporting filtering by industry, region, and risk flags.
    \item \textbf{Due Diligence Report}: An automated report generator that synthesizes financial health, risk signals, and AI-driven SWOT analysis for any selected company.
    \item \textbf{Market Entry Advisor}: A strategic planning tool that uses NLP to interpret queries (e.g., "Find fintech companies in Singapore") and recommends market entry strategies based on aggregate cluster data.
\end{enumerate}

% ============================================================
% 4. RESULTS
% ============================================================
\section{Results}
\label{sec:results}

\subsection{Exploratory Data Analysis}

\subsubsection{Distribution Analysis}

\begin{table}[H]
\centering
\caption{Company Size Distribution}
\label{tab:size_dist}
\begin{tabular}{lrr}
\toprule
\textbf{Employee Range} & \textbf{Count} & \textbf{Percentage} \\
\midrule
1-10 & 4,200 & 49\% \\
11-50 & 2,100 & 25\% \\
51-200 & 1,300 & 15\% \\
201-1000 & 650 & 8\% \\
1000+ & 309 & 4\% \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Correlation Analysis}

Key correlations observed:
\begin{itemize}[noitemsep]
    \item Revenue $\leftrightarrow$ Employees: $r = 0.65$
    \item Revenue $\leftrightarrow$ Market Value: $r = 0.72$
    \item Entity Score $\leftrightarrow$ Revenue: $r = 0.31$
\end{itemize}

\subsection{Company Segments}

K-Means clustering produced 5 distinct market segments (Table \ref{tab:clusters}):

\begin{table}[H]
\centering
\caption{Cluster Profiles}
\label{tab:clusters}
\begin{tabular}{llrrr}
\toprule
\textbf{Tier} & \textbf{Name} & \textbf{Count} & \textbf{Med. Revenue} & \textbf{Med. Employees} \\
\midrule
1 & Global HQ & 507 & \$45.2M & 1,250 \\
2 & Subsidiary & 2,012 & \$3.1M & 180 \\
3 & Subsidiary & 1,834 & \$850K & 65 \\
4 & Local HQ & 2,987 & \$280K & 22 \\
5 & Branch & 1,219 & \$12K & 3 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Lead Scoring Results}

\begin{table}[H]
\centering
\caption{Lead Tier Distribution}
\label{tab:leads}
\begin{tabular}{lcrr}
\toprule
\textbf{Tier} & \textbf{Score Range} & \textbf{Count} & \textbf{Percentage} \\
\midrule
Priority & 75-100 & 3 & 0.04\% \\
Hot & 50-74 & 425 & 5.0\% \\
Warm & 30-49 & 2,891 & 33.8\% \\
Cold & 0-29 & 5,240 & 61.2\% \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Risk Detection Results}

\begin{table}[H]
\centering
\caption{Risk Detection Summary}
\label{tab:risks}
\begin{tabular}{lr}
\toprule
\textbf{Risk Type} & \textbf{Count} \\
\midrule
Shell Companies (Rule-based) & 3,063 \\
Statistical Anomalies (Isolation Forest) & 428 \\
High-Risk Entities ($\geq$3 flags) & 244 \\
Orphan Subsidiaries & 89 \\
Data Quality Issues & 1,245 \\
\bottomrule
\end{tabular}
\end{table}

% ============================================================
% 5. DISCUSSION
% ============================================================
\section{Discussion and Commercial Value}
\label{sec:discussion}

\subsection{Strategic Insights}

Our analysis identifies three high-value company segments:
\begin{enumerate}[noitemsep]
    \item \textbf{High-Revenue, High-Productivity Firms}: 159 companies with Revenue $>$ \$100M
    \item \textbf{Complex but Efficient}: 87 companies with Family Size $>$ 100 and Rev/Emp $>$ \$50K
    \item \textbf{Outperforming SMBs}: 412 companies with Revenue $<$ \$1M but Revenue\_vs\_Industry $>$ 100\%
\end{enumerate}

\subsection{Commercial Applications}

The scalability of the proposed system supports diverse business use cases:

\subsubsection{Territory Planning for Sales Teams}
\textbf{Scenario}: A B2B software company needs to assign sales territories across Asia.\\[0.1cm]
\textbf{Solution}: By filtering for "Hot Leads" (Tier 2) and segmenting by Region, sales managers can mathematically balance potential revenue across territories. The "Lead Score" prioritizes which 50 companies a rep should call first, replacing intuition with data-driven probability.

\subsubsection{Pre-Acquisition Due Diligence}
\textbf{Scenario}: Private Equity firms evaluating potential manufacturing targets.\\[0.1cm]
\textbf{Solution}: The "Due Diligence Report" module instantly flags risks (e.g., Shell Company status, Orphan Subsidiary) and generates an AI-summarized financial health check. This reduces initial screening time from hours to seconds.

\subsubsection{Competitive Benchmarking}
\textbf{Scenario}: A mid-market CEO asks "How do we compare to peers?"\\[0.1cm]
\textbf{Solution}: Using cluster baselines, the system calculates relative performance (e.g., "Revenue per Employee is 45\% above the Tier 3 median"). This provides objective benchmarks for investor presentations and strategic planning.

\subsection{Limitations}

\begin{itemize}[noitemsep]
    \item Geographic bias toward Asian companies
    \item Missing financial data requires imputation (introduces uncertainty)
    \item Static clustering (could benefit from online learning)
    \item LLM responses depend on API availability
\end{itemize}

% ============================================================
% 6. CONCLUSION
% ============================================================
\section{Conclusion}
\label{sec:conclusion}

This project successfully developed a comprehensive company intelligence system that:
\begin{itemize}[noitemsep]
    \item Processed 8,559 company records with 72 attributes
    \item Engineered 15+ derived features
    \item Segmented companies into 5 interpretable tiers (Silhouette: 0.48)
    \item Implemented multi-factor lead scoring (0-100 scale)
    \item Detected 3,063 potential shell companies and 428 statistical anomalies
    \item Integrated LLM capabilities for natural language insights
\end{itemize}

The methodology demonstrates that systematic data processing, feature engineering, and machine learning can transform raw company data into actionable business intelligence, with clear commercial applications for sales, risk, and strategy functions.

% ============================================================
% REFERENCES
% ============================================================
\bibliographystyle{apalike}
\bibliography{references}

\end{document}
